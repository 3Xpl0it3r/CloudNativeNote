

#### 0x00 导读
&emsp;线程： 
- 多个线程共享一个虚拟内存，不需要内存管理单元处理上下文切换，线程通信通过共享内存---比进程轻量级
- 调度需要额外开销，每个线程占用1M内存，线程切换需要消耗内存
- 调度线程 恢复寄存器内存还需要向操作系统申请/释放资源--线程的上下文切换都需要消耗 ～1us 时间，但是go的调度对goroutine的切换减少为~0.2us,减少了80%的开销。

&emsp;go语言的调度器通过使用与cpu数量相等的线程减少线程频繁切换内存开销，同时在每个线程上执行额外开销更低的goroutine来降低操作系统和硬件的负载


#### 0x01 设计原理
&emsp;go调度器经历了几个版本:
- 单线程调度器 0.x 版本
- - 只包含40多行代码
- - 程序里面只存在一个活跃线程，由G-M 模型组成；

- 多线程调度器 1.0
- - 允许运行多线程的程序
- - 全局锁导致竞争严重

- 任务窃取调度器 1.1
- - 引入了处理器P，构成`G-M-P`模型 
- - 在处理器P 的基础上实现了基于工作窃取的调度器
- - 在某些情况下，goroutine 不会让出线程，进而造成了饥饿的问题
- - 时间过长的垃圾回收(STW)

- 抢占式调度器1.2-现在
- - 基于协作式的抢占式调度器1.2-1.3
- - > 通过编译器在函数调用的时候插入`抢占检查`指令，在函数调用的时候检查当前`goroutine`是否触发了抢占请求，实现基于协作式的抢占调度
- - > goroutine 可能会因为垃圾回收和循环长时间占用资源导致程序暂停

- - 基于信号的抢占式调度 1.14- now
- - > 实现了基于信号的真抢占式调度
- - > 垃圾回收在扫描栈时触发抢占调度
- - > 抢占的时间点不够多，还不能覆盖全部边缘情况

- 非均匀存储访问调度器-提案
- - > 对运行时的各种资源进行分区
- - > 实现非常复杂，到今天还没有提上日程

**单线程的调度器**
&emsp;单线程的调度器代码如下:
```c 
static void scheduler(void)
{
	G* gp;
	// Initialization.
	m->procid = getprocid();
	lock(&sched);
	if(gosave(&m->sched)){
	// 
	// Jumped here via gosave/gogo, so didn'
	// execute lock(&sched) above.
		lock(&sched);
		// Just finished running m->curg.
		gp = m->curg;
		gp->m = nil;	// for debugger
 		switch(gp->status){
 			case Grunnable:
			case Gdead:
			// Shouldn't have been running!
			throw("bad gp->status in sched");
			case Grunning:
				gp->status = Grunnable;
				gput(gp);
				break;
			case Gmoribund:
				gp->status = Gdead;
				if(--sched.gcount == 0)
					sys·exit(0);
				break;
		}
		notewakeup(&gp->stopped);
	}
// Find (or wait for) g to run.  Unlocks sched.
	gp = nextgandunlock();
	noteclear(&gp->stopped);
	gp->status = Grunning;
	m->curg = gp;
	gp->m = m;	// for debugger
	g = gp;
 	gogo(&gp->sched);
}
```
主要做如下事情:
- 获取调度器全局锁
- 调用`gosave`来保存栈寄存器和程序计数器
- 调用`runtime.nextgandunlock` 获取下一个需要运行的 `goroutine`并解锁调度器
- 修改全局线程`m`上要执行的goroutine
- 调用`runtime.gogo` 函数运行最新的`goroutine`


**多线程调度器**
&emsp;核心如下:
```c 
static void schedule(G *gp) {
	schedlock();
	if(gp != nil) {
		gp->m = nil;
		uint32 v = runtime·xadd(&runtime·sched.atomic, -1<<mcpuShift);
		if(atomic_mcpu(v) > maxgomaxprocs)
			runtime·throw("negative mcpu in scheduler");

		switch(gp->status){
		case Grunning:
			gp->status = Grunnable;
			gput(gp);
			break;
		case ...:
		}
	} else {
		...
	}
	gp = nextgandunlock();
	gp->status = Grunning;
	m->curg = gp;
	gp->m = m;
	runtime·gogo(&gp->sched, 0);
}
```
&emsp;整体逻辑和单线程调度器没有太多区别，程序里面可能有多个活跃线程，所以对线程调度器引入了`GOMAXPROCS`变量。问题
- 调度器的锁依然是全局锁，调度的状态是中心化存储的，锁竞争问题严重
- 线程需要经常互相传递可以运行的goroutine, 引入大量的延迟
- 线程需要处理内存缓存问题，导致大量的内存占用，影响数据的局部性
- 系统调用频繁阻塞和解除阻塞正在运行的线程，增加了额外的开销。


**任务窃取调度器**
&emsp;解决提议:
- 在当前的G-M 模型上引入了处理器P, 增加中间层
- 在处理器P的基础上实现了工作窃取的调度器

调度器代码如下:
```go 
static void schedule(void) {
    G *gp;
 top:
    if(runtime·gcwaiting) {
        gcstopm();
        goto top;
    }

    gp = runqget(m->p);
    if(gp == nil)
        gp = findrunnable();

    ...

    execute(gp);
}
```
- 如果当前运行时在等待垃圾回收，则在调用`gcstopm()`
```c 
static void
gcstopm(void)
{
	P *p;

	if(!runtime·gcwaiting)
		runtime·throw("gcstopm: not waiting for gc");
    // 如果m当前处于自旋状态，则推出自旋状态 
	if(m->spinning) {
		m->spinning = false;
		runtime·xadd(&runtime·sched.nmspinning, -1);
	}
    // 释放p/ 将p从m上剥离
	p = releasep();
	runtime·lock(&runtime·sched);
    // 将p 状态设置为pgcstop
	p->status = Pgcstop;
	if(--runtime·sched.stopwait == 0)
		runtime·notewakeup(&runtime·sched.stopnote);
	runtime·unlock(&runtime·sched);
    // 暂停m
	stopm();
}
```
- 调用`runtime.runqget()` 和`runtime.findrunnable()` 来从全局和本地中获取可运行的goroutine 来运行
- 调用`runtime.execute`在当前线程M上运行`goroutine`

&emsp;当前处理器本地的运行队列里面不包含goroutine的时候，调用`findrunnable`尝试找一个可运行的goroutine来运行，他会尝试从其他的`P`和全局队列里面获得一个

&emsp;运行时`G-M-P`模型中引入的处理器`P`是线程和`goroutine`的中间层，我们从它的结构体中就能看到处理器与`M`和`G`的关系
```go 
struct P {
	Lock;

	uint32	status;
	P*	link;
	uint32	tick;
	M*	m;
	MCache*	mcache;

	G**	runq;
	int32	runqhead;
	int32	runqtail;
	int32	runqsize;

	G*	gfree;
	int32	gfreecnt;
};
```
&emsp;处理器持有一个可运行的`goroutine`组成的环形运行队列，`runq`。还反向持有一个线程，调度器在调度的时候，会从处理器的队列中选择队列头的`goroutine`放到线程`M`上去执行。
```
M <-------- P --------> []G{g1, g2, g3}
            |
            |
           \|/
            runableG
```

**抢占式任务调度器**
&emsp;对go语言并发模型的修改提升了调度器的性能，但是在1.1里面仍然不支持抢占式调度，只能依靠goroutine主动让出CPU资源才能触发调度。go在1.2里面引入了基于协作式的抢占式调度，解决的问题如下:
- 某些goroutine可以长时间占用线程，造成其他的goroutine饥饿。
- 垃圾回收需要暂停整个程序，最长可能有几分钟，导致整个程序无法工作。
> 1.2版本的抢占式调度基于协作式的(无法覆盖一些边缘情况，例如for循环),在go1.14里面才用了基于信号抢占式调度解决掉。

**基于协作式的调度**
&emsp;go语言会在分段栈的机制上实现抢占式调度，利用编译器在分段栈上插入的函数，所有的`goroutine`在函数调用的时候都有机会进入运行时检查是否需要执行抢占，go通过提交了如下的特定实现了抢占式调度
&emsp;流程：
- 编译器会在调用函数之前插入`runtime.morestack`函数运行最新的
- go语言运行时会在垃圾回收暂停程序，系统监控发现goroutine运行超过10ms时发出抢占请求`stackPreempt`
- 当发生函数调用的时候，可能会执行编译器插入的`runtime.morestack`函数，它调用`runtime.newstack`会检查goroutine的字段是否设置为`StackPreempt`
- 如果`stackguard0`是`StackPreempt`就会触发抢占式让出当前线程。
&emsp;这种方式实现增加了运行时的复杂度，但是实现简单，也没有额外的过多的开销，这里的抢占式调度式通过编译器插入函数实现的，还是需要函数调用作为入口才能触发，所以这是一种协作式的抢占调度

**基于信号的抢占调度**
&emsp;基于协作式的调度虽然巧妙，但是不完备，在go1.14版本里面实现了非协作式的抢占式调度，在实现的过程中重构已经有的逻辑，并且在goroutine里面增加了新的状态和字段来支持抢占：
- `runtime:add general suspendG/resumeG`: 
- - 挂起goroutine的过程是在垃圾回收的栈扫描时候完成的，通过`runtime.suspendG`和`runtime.resumeG` 两个函数重构栈扫描这个过程的。
- - 调用`runtime.suspendG` 时候会将处于运行状态的goroutine的preemptStop标记为true。
- - 调用`runtime.preemptPark` 可以挂起当前goroutine, 并且将其状态更新为`_Gpremmpted`并且触发调度器的重新调度，改函数能够交出线程控制器

- `runtime:asynchronous preemption function for x86`
- - 在x86 架构上增加异步抢占的函数`runtime.asyncPreempt`和`runtime.asyncPreempt2`;
- `runtime.use signals to preempt Gs for suspendG`
- - 支持通过向线程发送信号的方式来暂停goroutine.
- - 在runtime.sighandler 函数注册sigure 信号的处理
- `runtime: implement async scheduler preemption`:
- - 修改`runtime.preepton` 函数实现，加入异步抢占逻辑

&emsp; 目前的抢占式调度只会在垃圾回收扫描任务时候触发，上面抢占调度流程如下:
- 程序启动的时，在`runtime.sighanlder`中注册`SIGURG`信号处理函数`runtime.doSigPreempt`
- 在触发垃圾回收的栈扫描时，会调用`runtime.suspendG` 挂起goroutine, 该函数会执行下面的逻辑:
- - 将`_Gruning`的状态的goroutine标记为可抢占，即将`preemptStop`设置为true。
- - 调用`runtime.preemptM`触发抢占
- `runtime.preemptM` 会调用`runtime.signalM`向线程发送信号`SIGURG`
- 操作系统会中断正在运行的线程，并执行预先注册的信号处理函数`runtime.doSigPreempt`
- `runtime.doSigPreempt`函数会处理信号抢占，获取当前的SP和PC 寄存器并调用`runtime.sigctxt.pushCall`函数
- `runtime.sigctxt.pushCall`会修改集群起，并且在程序返回用户态的时候执行`runtime.asyncPreempt`
- 汇编指令`runtime.asyncPreempt`会调用运行函数`runtime.asyncPreempt2`
- `runtime.asyncPreempt2`会调用函数 `runtime.preemptPark`
- `runtime.preemptPark`会修改当前goroutine状态到`_Gpremmpted`并且调用`runtime.schedule`让当前函数潜入休眠，并且让出线程。调度器会选择其他的goroutine继续执行。


#### 数据结构
&emsp;goroutune状态很多：
```go 
type g struct {
    // stack 描述了goroutine的栈内存范围[stack.lo, stack.hi)
    stack stack
    // stackguard0 可以用于调度器抢占式调度
    stackguard0 uintptr

    // 抢占信号
    preempt bool
    // 抢占时状态修改成`_Gpremmpted`
    preemptStop bool
    // 在同步安全点收缩栈
    preemptShrink bool

    // 最内侧的pannic 结构体
    _panic  *_panic 
    // _defer 最内侧的延迟函数结构体
    _defer  *_defer

    // m表示当前goroutine占用的线程，可以为空
    m       *m
    // aotmicstatus goroutine的状态
    atomicstatus        uint32
    // 存储goroutine的调度相关的数据结构
    sched           gobuf
    // goroutineid, 该字段对开发者不见
    goid            int64
}


// gobuf这些内容会在调度器保存后者回复上下文的时候会用到，其中栈指针和程序计数器用来存储或回复寄存器中的值，即改变程序即将执行的代码
type gobuf stuct {
    // 栈指针
    sp          uintptr
    // 程序计数器
    pc          uintptr
    // 持有runtime.gobuf的goroutine
    g           guintptr
    // 系统调用的返回值
    ret         sync.Uintreg
}
```
&emsp;结构体`runtime.g`的atomicstatus字段存储了当前goroutine的状态，除了几个不被使用以及和`gc`相关的状态外，goroutine可能处于下面几个状态
```go
	// _Gidle means this goroutine was just allocated and has not
	// yet been initialized.
	// 刚刚被分配，还没有完成初始化
	_Gidle = iota // 0

	// 没有执行代码，没有栈所有权，存储在运行队列里面
	_Grunnable // 1

	// 可以执行用户代码， 拥有栈所有权，被赋予了内核线程M和处理器P
	_Grunning // 2

	// 正在执行系统调用，拥有栈的所有权，没有执行用户代码，被赋予了内核线程M，但是不在运行队列上面
	_Gsyscall // 3

	// 由于运行时而被阻塞，没有执行用户代码，而且不在运行队列上面，可能处于等待 channel 当中
	_Gwaiting // 4

	// _Gmoribund_unused is currently unused, but hardcoded in gdb
	// scripts.
	_Gmoribund_unused // 5

	// 没有被使用，没有执行代码，可能有分配的栈
	_Gdead // 6

	// _Genqueue_unused is currently unused.
	_Genqueue_unused // 7

	// 栈正在被拷贝，没有执行代码，不在运行队列上面
	_Gcopystack // 8

	// 由于被抢占了而被阻塞，没有执行用户代码，而不在运行队列上面，等待被唤醒
	_Gpreempted // 9

	// GC正在扫描栈空间，没有执行任何代码，可以和其他的状态并存
	_Gscan          = 0x1000
```
&emsp;goroutine的状体比较多，聚合下三种：等待中，可运行，运行中
- 等待中: goroutine正在等待某些条件满足，例如:系统调用结束等包括`_Gwaiting, _Gsyscall, _Gpreempted`几个状态
- 可运行: goroutine已经准备就绪，可以在线程运行，如果当前程序中有很多goroutine, 每个goroutine 就有可能等待更多的时间，即`_Grunnable`
- 运行中: goroutine 正在某个线程上运行即，`_Grunning`
```bash
Gidle -----------> Gdead <---------------> Gsyscall
                    |    <-----|----------->
                    |          |
                    |         Gunning <------------------> Gcopystack
                    |          |
                    |   |----------------------|
                   \|/ \|/                    \|/
                   Grunning <-------------> Gwaiting
                

```

**M**
&emsp;go语言里面的并发模型中`M`是操作系统线程。调度器最多可以创建10000个线程，但是其中大多数的线程都不会执行用户代码(可能会陷入系统调用),最多只有`GOMAXPROCS`个活跃线程可以正常执行:
&emsp;在默认的情况下，运行时会将`GOMAXPROCS`设置成当前机器的核心数，用户也可以在程序中`runtime.GOMAXPROCS`来改变最大活跃线程数。例如：默认情况下一个四核机器会创建四个活跃的操作系统线程，每个线程都对应其中一个运行时的runtime.m结构体, 在大多数情况下，都会使用go默认设置，也就是线程数=cpu个数，默认配置不会频繁的触发操作系统的线程调度和上下文切换，所有的调度都会发生在用户态，由go语言调度，能够减少很多额外的开销。
&emsp;数据结构如下:
```go 
type m struct {
    // g0是持有调度栈的`goroutine`
    g0      *g 
    // curg 是当前线程上运行的用户goroutine, 这两个goroutine是操作系统线程唯一关心的两个goroutine
    curg    *g

    // 正在运行代码的处理器
    p       puintprt
    // 暂存的处理器
    nextp   puintprt
    // 执行系统调用之前使用线程的处理器
    oldp    puintprt
}
```
&emsp;g0是一个特色的goroutine,深度参与运行时的调度过程，包括goroutine的创建，大内存的分配和`CGO`函数的执行。

**P**
&emsp;调度器中`P`是线程和`goroutine`的中间层，它可以提供线程需要的上下文环境，也负责调度线程上的等待队列，通过处理器P的调度，每个内核线程都能运行执行多个`goroutine`它能在goroutine进行一些`I/O`操作时及时让出计算资源，提高线程利用效率。
&emsp;因为调度器在启动时候就会创建`GOMAXPROCS`个处理器，所以`go`语言程序的处理器数量一定会等于`GOMAXPROCS`，这些处理器会绑定到不同的内核线程上
&emsp;`runtime.p`是处理器的运行时表示，作为调度器的内部实现，他包含的字段非常多包括性能追踪，垃圾回收，和计时器相关的字段，这些字段也非常重要，
```go 
type p struct {
    m       muintptr
    runqhead            uint32
    runqtail            uint32
    runq                [256]guiintpr
    runnext             guintper
}
```
&emsp;p反向存储的线程维护着线程与处理器的关系，而`runqhead, runqtail runq`三个字段表示处理器持有的运行队列，其中存储着待执行的`goroutine列表`, `runnext`表示下一个需要执行的goroutine. runtime.p主要有一下几个状态
```go 
_Pidle                  // 处理器没有运行用户的代码，或者调度器，被空闲队列或者改变其状态的结构持有，运行队列为空
_Prunning               // 被线程M持有，并且正在执行用户代码或者调度器
_Psyscall               // 没有执行用户代码，当前线程陷入了系统调用，
_Pgcstop                // 被线程M持有，当前处理器由于垃圾回收被停止
_Pdead                  // 当前处理器已经不被使用了
```

#### 调度器的启动
```go 
func schedinit() {
	// raceinit must be the first call to race detector.
	// In particular, it must be done before mallocinit below calls racemapshadow.
	_g_ := getg()
	if raceenabled {
		_g_.racectx, raceprocctx0 = raceinit()
	}

	// 这是go语言所能创建的最大的线程数， 但是可以通过`GOMAXPROCS`来控制
	sched.maxmcount = 10000

	procs := ncpu
	if n, ok := atoi32(gogetenv("GOMAXPROCS")); ok && n > 0 {
		procs = n
	}
	// 通过procresize 来更新程序中处理器的数量，这个过程里面不会执行任何用户代码，调度器也会进入锁状态
	if procresize(procs) != nil {
		throw("unknown runnable goroutine during bootstrap")
	}
    .......
}
```
&emsp;`procresize`的流程如下:
```go 
func procresize(nprocs int32) *p {
	// 获取当前最大的线程数
	old := gomaxprocs
	if old < 0 || nprocs <= 0 {
		throw("procresize: invalid arg")
	}
	if trace.enabled {
		traceGomaxprocs(nprocs)
	}

	// update statistics
	now := nanotime()
	if sched.procresizetime != 0 {
		sched.totaltime += int64(old) * (now - sched.procresizetime)
	}
	sched.procresizetime = now

	// Grow allp if necessary.
	// 如果nprocs 要比p多，
	if nprocs > int32(len(allp)) {
		// Synchronize with retake, which could be running
		// concurrently since it doesn't run on a P.
		// 枷锁
		lock(&allpLock)
		if nprocs <= int32(cap(allp)) {
			// 如果nprocs 要比allp的容量小，则重新缩小allp的个数
			allp = allp[:nprocs]
		} else {
			// 否则扩容
			nallp := make([]*p, nprocs)
			// Copy everything up to allp's cap so we
			// never lose old allocated Ps.
			copy(nallp, allp[:cap(allp)])
			allp = nallp
		}
		unlock(&allpLock)
	}

	// initialize new P's
	for i := old; i < nprocs; i++ {
		// 初始化新扩容的p
		pp := allp[i]
		if pp == nil {
			// 创建新的p
			pp = new(p)
		}
		//  p执行初始化工作
		pp.init(i)
		atomicstorep(unsafe.Pointer(&allp[i]), unsafe.Pointer(pp))
	}

	// 获取当前g
	_g_ := getg()
	if _g_.m.p != 0 && _g_.m.p.ptr().id < nprocs {
		// 如果当前的p 不为空，并且当前p的id 要比nprocs 小，说明这个p是扩容之前i就已经存在的了，那么继续使用当前的p
		// continue to use the current P
		_g_.m.p.ptr().status = _Prunning
		_g_.m.p.ptr().mcache.prepareForSweep()
	} else {
		// 如果不是第一种情况，那么释放当前的p,并且获取allp[0]
		// release the current P and acquire allp[0].
		//
		// We must do this before destroying our current P
		// because p.destroy itself has write barriers, so we
		// need to do that from a valid P.
		// 在销毁当前p之前，需要做一些清理工作，p自我销毁会有个写屏障
		if _g_.m.p != 0 {
			// 如果当前的p不为空， 将当前p.m设置为0
			if trace.enabled {
				// Pretend that we were descheduled
				// and then scheduled again to keep
				// the trace sane.
				traceGoSched()
				traceProcStop(_g_.m.p.ptr())
			}
			_g_.m.p.ptr().m = 0
		}
		_g_.m.p = 0
		_g_.m.mcache = nil
		p := allp[0]
		p.m = 0
		p.status = _Pidle
		acquirep(p)
		if trace.enabled {
			traceGoStart()
		}
	}

	// release resources from unused P's
	for i := nprocs; i < old; i++ {
		p := allp[i]
		p.destroy()
		// can't free P itself because it can be referenced by an M in syscall
	}

	// Trim allp.
	if int32(len(allp)) != nprocs {
		lock(&allpLock)
		allp = allp[:nprocs]
		unlock(&allpLock)
	}

	var runnablePs *p
	for i := nprocs - 1; i >= 0; i-- {
		p := allp[i]
		if _g_.m.p.ptr() == p {
			continue
		}
		p.status = _Pidle
		if runqempty(p) {
			pidleput(p)
		} else {
			p.m.set(mget())
			p.link.set(runnablePs)
			runnablePs = p
		}
	}
	stealOrder.reset(uint32(nprocs))
	var int32p *int32 = &gomaxprocs // make compiler check that gomaxprocs is an int32
	atomic.Store((*uint32)(unsafe.Pointer(int32p)), uint32(nprocs))
	return runnablePs
}
```
&emsp;主要流程如下:
- 根据需求来决定是扩容还是缩容`allp`
- 如果当前g绑定的m对应的p存在，则继续运行当前的处理器，否则将`allp[0]`和当前的线程做绑定
- 释放其他的`allp`


#### 创建goroutine
&emsp;启动一个`goroutine`来执行任务的时候，需要通过`go`关键字来做，编译器会通过`cmd/compile/internal/gc.state.stmt`和`cmd/compile/internal/gc.state.call` 这两个方法将`go`关键字转化为`runtime.newproc`函数调用。
```go 
func (s *state) call(n *Node, k callKind) *ssa.Value {
	if k == callDeferStack {
		...
	} else {
		switch {
		case k == callGo:
			call = s.newValue1A(ssa.OpStaticCall, types.TypeMem, newproc, s.mem())
		default:
		}
	}
	...
}
```

&emsp;`runtime.newproc`的入参是参数大小和表示函数的指针`funcval`,它获取goroutine和调用方的程序计数器，然后调用 `runtime.newproc1`函数获取新的`goroutine`结构，将其加入到处理器的运行队列里面，并且在满足条件的时候调用`runtime.wakeup` 唤醒处理执行`goroutine`。
> 在go1.15里面逻辑稍微有点不一样了，在`runtime.newproc`里面调用`runtime.newproc1`， 在`runtime.newproc1`里面获取一个新的goroutine结构体，在满足条件的时候调用`runtme.wakeup`唤醒执行goroutine

&emsp;`newproc1`会根据传入的参数初始化一个`g`结构体，主要拆分下面几个阶段:
- 获取或者创建新的`goroutine`结构体 
- 将传入的参数转移到`goroutine`的栈上 
- 更新`goroutine`调度相关属性
```go 
// 精简后代码如下:

func newproc1(fn *funcval, argp unsafe.Pointer, narg int32, callergp *g, callerpc uintptr) {
	// 获取当前goroutine
	_g_ := getg()

	
	
	// siz 参数的内存空间， narg 参数的大小
	siz := narg
	siz = (siz + 7) &^ 7

	// 从当前`_p_`本地队列里面获取一个g，如果本地队列为空，则从全局里面获取一个
	newg := gfget(_p_)
	if newg == nil {
		// 如果获取不到g， 那么创建一个新有足够栈大小的g
		newg = malg(_StackMin)
	}
	
	if narg > 0 {
		// 调用memmove 将fn函数的所有参数拷贝到栈上。argp 和 narg 分别是参数的内存空间和大小。
		// memmove 函数模型： func memmove(to, from unsafe.Pointer, n uintptr)
		memmove(unsafe.Pointer(spArg), argp, uintptr(narg))
	}

	// 更新
	newg.sched.sp = sp
	newg.stktopsp = sp
	//  设置调度信息
	// 将程序计数器设置为goexit
	newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function
	// 将sched.g 设置为刚刚新创建的goroutine
	newg.sched.g = guintptr(unsafe.Pointer(newg))
	// 这个里面做二次处理，调度器里面最终sp存了goexit的程序计数器，在sched里面的pc存储了fn程序计数器
	gostartcallfn(&newg.sched, fn)

	// 将创建的g放到，这个可能是全局队列，也有可能是处理器的局部dui li
	runqput(_p_, newg, true)

	if atomic.Load(&sched.npidle) != 0 && atomic.Load(&sched.nmspinning) == 0 && mainStarted {
		wakep()
	}
	releasem(_g_.m)
}
```


**初始化结构体**
&emsp;`gfget`通过两种不同的方式来获取新的`runtime.g`.
```go 
func gfget(_p_ *p) *g {
retry:
	// 如果当前p free list里面为空，但是调度器的gFree list 不为空， 从调度器gfreelist 里面取32个goroutine 到p freelist里面。
	if _p_.gFree.empty() && (!sched.gFree.stack.empty() || !sched.gFree.noStack.empty()) {
		lock(&sched.gFree.lock)
		for _p_.gFree.n < 32 {
			// Prefer Gs with stacks.
			gp := sched.gFree.stack.pop()
			if gp == nil {
				gp = sched.gFree.noStack.pop()
				if gp == nil {
					break
				}
			}
			sched.gFree.n--
			_p_.gFree.push(gp)
			_p_.gFree.n++
		}
		unlock(&sched.gFree.lock)
		goto retry
	}
	//此时_p_.gFree 列表里面获取一个g
	gp := _p_.gFree.pop()
	if gp == nil {
		return nil
	}
	_p_.gFree.n--
	// 开始设置栈
	return gp
}
```
&emsp;但是当gfree里面取不到的时候，它会调用`malg`来初始化新的`g`结构体。如果申请的堆栈大于0， 会申请2KB的栈空间
```go 
// Allocate a new g, with a stack big enough for stacksize bytes.
func malg(stacksize int32) *g {
	newg := new(g)
	if stacksize >= 0 {
		stacksize = round2(_StackSystem + stacksize)
		systemstack(func() {
			newg.stack = stackalloc(uint32(stacksize))
		})
		newg.stackguard0 = newg.stack.lo + _StackGuard
		newg.stackguard1 = ^uintptr(0)
		// Clear the bottom word of the stack. We record g
		// there on gsignal stack during VDSO on ARM and ARM64.
		*(*uintptr)(unsafe.Pointer(newg.stack.lo)) = 0
	}
	return newg
}

```
&emsp;总结下，runtime.newproc1 函数会从处理器或者调度器缓存中获取新的结构体，可以调用`runtime.malg`来创建，



**运行队列**
&emsp;`runtime.runqput` 会将`goroutine`放到运行队列上，这既可能是全局的运行队列，也有可能是处理器的运行队列(精简后的代码如下)。
```go 
func runqput(_p_ *p, gp *g, next bool) {
	if next {
		// 如果next为true，那么将goroutine 设置到处理器的runnext 作为下一个处理器执行的任务。
	retryNext:
		oldnext := _p_.runnext
	}

	if t-h < uint32(len(_p_.runq)) {
		// runq 里面还剩下空余的
		_p_.runq[t%uint32(len(_p_.runq))].set(gp)
		return
	}
    // 如果runq里面没有足够的空间存储g了，会把本地的一般的goroutine 和 待加入的goroutine 加入到 全局队列里面
	runqputslow(_p_, gp, h, t)
```
&emsp;runq是一个数组构成的环形链表，总共可以存储256个goroutine
&emsp;总结，go语言有两个运行队列，其中一个是处理器的本地队列，另外一个是调度器持有的全局队列，只有在本地队列时没有剩余空间的时候才会使用全局队列。

**调度信息**
&emsp;运行时创建goroutine时会通过代码代码设置调度相关的信息
```go 
	//  设置调度信息
	// 将程序计数器设置为goexit
	newg.sched.pc = funcPC(goexit) + sys.PCQuantum // +PCQuantum so that previous instruction is in same function
	// 将sched.g 设置为刚刚新创建的goroutine
	newg.sched.g = guintptr(unsafe.Pointer(newg))
```
&emsp;上面的调度信息`sched`不是初始化后的goroutine的最终结果，它还需要经过`runtime.gostartcallfn`和`runime.gostartcall`处理
```go 
// adjust Gobuf as if it executed a call to fn
// and then did an immediate gosave.
func gostartcallfn(gobuf *gobuf, fv *funcval) {
	gostartcall(gobuf, fn, unsafe.Pointer(fv))
}

func gostartcall(buf *gobuf, fn, ctxt unsafe.Pointer) {
	sp := buf.sp		//  
	if sys.RegSize > sys.PtrSize {
		sp -= sys.PtrSize
		*(*uintptr)(unsafe.Pointer(sp)) = 0
	}
	sp -= sys.PtrSize
	*(*uintptr)(unsafe.Pointer(sp)) = buf.pc		// sp 存储了goexit函数的程序计数器
	buf.sp = sp
	buf.pc = uintptr(fn) 			// pc里面存储了传入函数的计数器
	buf.ctxt = ctxt
}
```
&emsp;调度器的sp中存储了`runtime.goexit`函数的程序计数器，而pc中存储l了传入函数的计数器,sp里面存储了`runtime.goexit`会让人觉得困惑。

#### 调度循环
&emsp;调度器启动后，go语言运行时会调用`runtime.mstart`以及`runtime.mstart1`，前者会初始化`g0`的`stackguard0`和`stackguard1`这两个字段，后者会初始化线程并调用`runtime.schedule`进入调度循环
```go 
func mstart() {
	// 获取当前的goroutine
	_g_ := getg()
	// Initialize stack guard so that we can start calling regular
	// Go code.
	// 初始化stack guard字段
	_g_.stackguard0 = _g_.stack.lo + _StackGuard
	// This is the g0, so we can also call go:systemstack
	// functions, which check stackguard1.
	_g_.stackguard1 = _g_.stackguard0
	// 调用mstart1()
	mstart1()
	mexit(osStack)
}
```
&emsp;`rntime.schedule`函数会从下面几个地方查找待执行的goroutine
- 为了保证公平，当全局队列中有等待执行的`goroutine`，通过`schedtick`保证有一定几率会从全局的运行队列里面查找对应的goroutine
- 从处理器本地的运行队列中查找待执行的goroutine
- 如果前两种方法都没有找到goroutine,会通过`runtime.findrunnable`进行阻塞的查找`goroutine`
```go 

// One round of scheduler: find a runnable goroutine and execute it.
// Never returns.
func schedule() {
	// 获取当前的g
	_g_ := getg()

top:
	//  获取处理器p
	pp := _g_.m.p.ptr()
	// 禁用异步抢占模式
	pp.preempt = false
	if gp == nil {
		// Check the global runnable queue once in a while to ensure fairness. 	// 为了保证公平，有一定的概率会触发 在全局队列里面检查是否有可运行的goroutine
		// Otherwise two goroutines can completely occupy the local runqueue 	// 否则两个goroutine会通过不断的再生，会完全占用本地队列
		// by constantly respawning each other.
		// 为保证公平，当全局队列中有等待执行的goroutine,通过schedtick 保证有一定的几率从全局队列里面查找对应的goroutine
		if _g_.m.p.ptr().schedtick%61 == 0 && sched.runqsize > 0 {
			lock(&sched.lock)
			gp = globrunqget(_g_.m.p.ptr(), 1)
			unlock(&sched.lock)
		}
	}
	if gp == nil {
		gp, inheritTime = runqget(_g_.m.p.ptr())	// 从处理器的本地运行队列中查找等待执行的goroutine
	}
	if gp == nil { 	// 如果上面两种方法都没有查找到goroutine, 则会通过runtime.findrunnable 进行阻塞查找goroutine
		gp, inheritTime = findrunnable() // blocks until work is available
	}

	execute(gp, inheritTime)			// 永远不会退出
}
```
&emsp;`runtime.findrunnable`实现比较复杂，主要通过下面几种方式来获取goroutine的
- 从本地运行队列，全局运行队列中查找是否有goroutine,
- 从网络轮询器中查找是否有goroutine等待运行
- 通过`runtime.runqsteal`尝试从其他随机处理器中窃取等待运行的`goroutine`，该函数还可能窃取处理器的计时器
> 这个函数一定会阻塞等待，一直到可以找到一个可运行的goroutine的，如果找不到会一直阻塞住。

&emsp;接下来由`runtime.execute`执行获取的goroutine.,准备工作好了之后，它会通过`runtime.gogo`将goroutine 调度到当前线程之上。
```go 
func execute(gp *g, inheritTime bool) {
	_g_ := getg()

	// Assign gp.m before entering _Grunning so running Gs have an
	// M.
	_g_.m.curg = gp
    // 将gp 和 当前goroutine运行的线程绑定
	gp.m = _g_.m
	// 将goroutine的状态从runnable 更新为running
	casgstatus(gp, _Grunnable, _Grunning)
	gogo(&gp.sched)
}
```
&emsp;`gogo`函数原型`func gogo(buf *gobuf)`
```asm 
// func gogo(buf *gobuf)
// 调度器.sp 存储goexit 函数计数器， go.pc 存储了需要调用的函数指针(用户代码)
// restore state from Gobuf; longjmp
TEXT runtime·gogo(SB), NOSPLIT, $16-8
	MOVQ	buf+0(FP), BX		// gobuf，  // 获取调度器信息
	MOVQ	gobuf_g(BX), DX     // // 将gobuf.g 存放到DX 里面
	MOVQ	0(DX), CX		// make sure g != nil， 将DX第一个字段存放到CX里面， 栈信息 type stack struct{lo uintptr, hi uintprt}
	get_tls(CX)
	MOVQ	DX, g(CX)       // 将gobuf.g 填充到CX里面
	MOVQ	gobuf_sp(BX), SP	// restore SP       // gobuf的sp 是goexit的程序计数器
	MOVQ	gobuf_ret(BX), AX       //
	MOVQ	gobuf_ctxt(BX), DX      // gobuf.ctxt 存放了原始的用户代码的函数指针
	MOVQ	gobuf_bp(BX), BP
	MOVQ	$0, gobuf_sp(BX)	// clear to help garbage collector
	MOVQ	$0, gobuf_ret(BX)
	MOVQ	$0, gobuf_ctxt(BX)
	MOVQ	$0, gobuf_bp(BX)
	MOVQ	gobuf_pc(BX), BX        // gobuf.pc 存放了用户函数的指针
	JMP	BX                          // 开始执行用户函数

```
&emsp;go函数的调用约定，是将返回地址放入到栈SP上面，然后跳转到目标函数，当目标函数返回后，会从栈上查找调用的地址，并跳回调用方继续执行剩下的代码。也就执行完了之后，会跳转到goexit函数去执行
```asm 
// The top-most function running on a goroutine
// returns to goexit+PCQuantum.
TEXT runtime·goexit(SB),NOSPLIT,$0-0
	CALL	runtime·goexit1(SB)	// does not return
```
&emsp;goexit本质上会调用`goexit1`函数执行
```go 
func goexit1() {
	mcall(goexit0)
}
```
&emsp;`goexit1` 调用`mcall(goexit0)`函数, 在这里面有两个函数`mcall()`和`goexit0()`, 我们查看下`mcall`函数的注释
```go 
// mcall switches from the g to the g0 stack and invokes fn(g), // 将g切换到g0栈，然后调用fn(g)
func mcall(fn func(*g))
```
&emsp;也就上面函数最终会在g0的栈上面执行`goexit0`函数，我们看下`goexit0`函数，下面精简后的代码如下:
```go 
// goexit continuation on g0.
func goexit0(gp *g) {
	_g_ := getg() 	//获取当前的 goroutine, (这个goroutine也就是之前执行的那个goroutine)

	// 将g的状态从running 设置为dead
	casgstatus(gp, _Grunning, _Gdead)
	if isSystemGoroutine(gp, false) {
		atomic.Xadd(&sched.ngsys, -1)
	}
	// 下面操作清空goroutine信息
    ......
	// 解除g和m的关联信息
	dropg()

	// 将g重新放回p的freelist队列里面
	gfput(_g_.m.p.ptr(), gp)
	//重新进入新一轮的调度
	schedule()
}
```

#### 调度器的触发
&emsp;因为调度器的`runtime.schedule`会重新选择goroutine到线程去执行，因此只需要找到所有的函数调用方法就能找到所有的触发调度器的点。主要有以下几个触发点:
```txt
	/*
	触发的逻辑/触发的时间点

	系统监控			semrelease  --------->  semrelease1 ------> goyield ---------> goyield_m
	协作式调度 		godched		--------->  gosched_m -----> 					goschedImpl
	系统调用 		exitsyscall ---------> 	exitsyscall0
	主动挂起			gopark 		---------> 					park_m

	 */

```

**主动挂起** 
&emsp;主动挂起是常见 `gopark`是最常见的调度方式，它会将当前的goroutine暂停掉，被暂停的任务不会放回到队列里面



**系统调用**
&emsp;系统调用也会触发调度器的调度，为了处理特色的调用，我们甚至在goroutine里面加入了`_Gsyscall`状态，go通过`syscall.Syscall和syscall.RawSyscall`等使用汇编语言编写的方法封装操作系统提供的系统调用

